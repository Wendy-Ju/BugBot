{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE DESCRIPTION: -------------------------------------------------------\n",
    "\n",
    "# This file builds, trains and evaluates a CNN model and 6 other pretrained \n",
    "# models using transfer learning. The following models ran were EfficientNet, \n",
    "# ResNet50, VGG16, MobileNetV2, Xception, and DenseNet201.\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# ----------- IMPORTS ----------------\n",
    "\n",
    "# Libraries for building convolutional neural network and transfer learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0, VGG16, MobileNetV2, Xception, DenseNet201\n",
    "\n",
    "# Libaries for evaluation performance metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, RocCurveDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Utility libraries\n",
    "import os\n",
    "from IPython.display import display\n",
    "import time\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "\n",
    "# ----------- CONSTANTS ----------------\n",
    "\n",
    "# Directory structure\n",
    "TRAIN_DIR = \"PROCESSED_DATA/TRAINING_DATA/TRAINING_AUGMENTED_DATA\"\n",
    "VALID_DIR = \"PROCESSED_DATA/VALIDATION_DATA/\"\n",
    "TEST_DIR = \"PROCESSED_DATA/TEST_DATA/\"\n",
    "\n",
    "# Image parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Load in data\n",
    "DATAGEN = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Training parameters\n",
    "#MODEL_OPTIONS = [\"ResNet50\", \"EfficientNet\", \"VGG16\", \"MobileNetV2\", \"Xception\", \"DenseNet201\"]\n",
    "MODEL_OPTIONS = [\"ResNet50\", \"EfficientNet\"]\n",
    "DEFAULT_LR = 0.0001\n",
    "DEFAULT_EPOCHS = 1\n",
    "DEFAULT_DROPOUT = 0.5\n",
    "\n",
    "# Sound settings\n",
    "PLAY_SOUND_FLAG = True\n",
    "\n",
    "# ----------- DATA LOADING FUNCTION ----------------\n",
    "\n",
    "def load_data(directory,shuffle_flag=True):\n",
    "    generator = DATAGEN.flow_from_directory(\n",
    "    directory,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',shuffle=shuffle_flag)\n",
    "    return generator\n",
    "\n",
    "# Initialize data generators\n",
    "TRAIN_GENERATOR = load_data(TRAIN_DIR)\n",
    "VAL_GENERATOR = load_data(VALID_DIR)\n",
    "TEST_GENERATOR = load_data(TEST_DIR,shuffle_flag=False)\n",
    "EVAL_VAL_GENERATOR = load_data(VALID_DIR, shuffle_flag=False)\n",
    "\n",
    "\n",
    "\n",
    "# ----------- MODEL BUILDING Functions -------------------\n",
    "\n",
    "def build_cnn(dropout_percent: float = DEFAULT_DROPOUT) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Builds a standard convolutional neural network model\n",
    "\n",
    "    Parameters:\n",
    "        dropout_percent (float, optional): The percentage of dropout. Defaults to DEFAULT_DROPOUT.\n",
    "\n",
    "    Returns:\n",
    "        a keras CNN model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(dropout_percent),\n",
    "        Dense(TRAIN_GENERATOR.num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_transfer_learning(model_name: str, dropout_percent: float = DEFAULT_DROPOUT) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Builds and implements a transfer learning model using a pretrained model\n",
    "\n",
    "    Parameters:\n",
    "        model_name - str: name of pretrained model (e.g., DenseNet201)\n",
    "        dropout_percent - float: percentage of dropout\n",
    "\n",
    "    Returns:\n",
    "        a keras transfer learning model\n",
    "    \"\"\"\n",
    "    \n",
    "    if model_name == 'ResNet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        \n",
    "    elif model_name == 'EfficientNet':\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        \n",
    "    elif model_name == 'VGG16':\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        \n",
    "    elif model_name == 'MobileNetV2':\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        \n",
    "    elif model_name == 'Xception':\n",
    "        base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        \n",
    "    elif model_name == 'DenseNet201':\n",
    "        base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name. Choose from 'ResNet50', 'EfficientNet', 'VGG16', 'MobileNetV2', 'Xception', or 'DenseNet201'\")\n",
    "\n",
    "    # freeze the base model layers\n",
    "    base_model.trainable = False  \n",
    "    \n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(dropout_percent)(x)\n",
    "    \n",
    "    output_layer = Dense(TRAIN_GENERATOR.num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def full_build_cnn(\n",
    "    use_transfer_learning: bool = False, \n",
    "    transfer_model_name: str = 'ResNet50', \n",
    "    lr: float = DEFAULT_LR,\n",
    "    metrics_lst: list = ['accuracy'], \n",
    "    val_generator = VAL_GENERATOR, \n",
    "    epoch_num: int = DEFAULT_EPOCHS,\n",
    "    play_sound_flag: bool = True, \n",
    "    dropout_percent: float = DEFAULT_DROPOUT\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Builds and trains a CNN model\n",
    "\n",
    "    Parameters:\n",
    "        use_transfer_learning - bool: indicating if this model should use transfer learning\n",
    "        transfer_model_name - str: pretrained model name\n",
    "        lr - float: denoting learning rate\n",
    "        metrics_lst list: list of metrics to use in model compilation (accuracy)\n",
    "        val_generator: validation data generator from load_data function\n",
    "        epoch_num - int: number of epochs\n",
    "        play_sound_flag -bool: plays sound after training is done\n",
    "        dropout_percent -float: dropout percentage\n",
    "\n",
    "    Returns:\n",
    "        model - keras model object\n",
    "        training_history - keras model training history\n",
    "    \"\"\"\n",
    "    \n",
    "    if use_transfer_learning:\n",
    "        model = build_transfer_learning(transfer_model_name, dropout_percent=dropout_percent)\n",
    "        \n",
    "    else:\n",
    "        model = build_cnn(dropout_percent=dropout_percent)\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=metrics_lst)\n",
    "    \n",
    "    # training\n",
    "    training_history = model.fit(\n",
    "        TRAIN_GENERATOR,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epoch_num\n",
    "    )\n",
    "\n",
    "    if play_sound_flag == True:\n",
    "        \n",
    "        # Sound that plays after training model is finished\n",
    "        repeat_times = 3  \n",
    "        if os.name == 'posix':  # For macOS and Linux\n",
    "            for _ in range(repeat_times):\n",
    "                os.system('afplay /System/Library/Sounds/Glass.aiff')  # macOS\n",
    "                # Linux users: os.system('aplay /path/to/sound.wav')\n",
    "                \n",
    "    return model, training_history\n",
    "\n",
    "\n",
    "def evaluate_model(model: tf.keras.Model, filename: str = \"pest_classifier_cnn.h5\") -> tuple:\n",
    "    \"\"\"\n",
    "    Saves model to h5 file, returns validation accuracy loss and validation accuracy\n",
    "\n",
    "    Parameters:\n",
    "        model - keras model: model to evaluate.\n",
    "        filename -str: filename to save the model\n",
    "\n",
    "    Returns:\n",
    "        tuple: containing the validation loss and validation accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # evaluate on validation data\n",
    "    val_loss, val_acc = model.evaluate(VAL_GENERATOR)\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # save to file\n",
    "    model.save(filename)\n",
    "    \n",
    "    return val_loss, val_acc\n",
    "\n",
    "\n",
    "\n",
    "# ----------- MODEL EVALUATION Functions ------\n",
    "\n",
    "def create_classification_report(y_true, y_pred, class_indices: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a classification report\n",
    "\n",
    "    Parameters:\n",
    "        y_true: true class labels\n",
    "        y_pred: predicted class labels\n",
    "        class_indices: mapping of class labels to class names.\n",
    "\n",
    "    Function:\n",
    "        generates a classification report including precision, recall, F1-score, and accuracy for each class\n",
    "        outputs the report as a DataFrame for further analysis\n",
    "\n",
    "    Returns:\n",
    "        dataframe - classification report\n",
    "    \"\"\"\n",
    "\n",
    "    report = classification_report(y_true, y_pred, target_names=list(class_indices.keys()), output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    print(\"Classification Report:\")\n",
    "    display(report_df)\n",
    "    return report_df\n",
    "\n",
    "    \n",
    "def plot_confusion_matrix(y_true, y_pred, class_indices: dict) -> None:\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix\n",
    "\n",
    "    Parameters:\n",
    "        y_true: true class labels\n",
    "        y_pred: predicted class labels\n",
    "        class_indices: Mapping of class labels to class names\n",
    "\n",
    "    Function:\n",
    "        Plots a confusion matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_indices.keys()))\n",
    "    disp.plot(cmap=plt.cm.Blues, colorbar=True)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_loss_curves(training_history: tf.keras.callbacks.History) -> None:\n",
    "    \"\"\"\n",
    "    Plots two plots: training and validation accuracy and loss curves\n",
    "\n",
    "    Parameters:\n",
    "        training_history: object from model.fit() training history containing metrics accuracy and loss\n",
    "\n",
    "    Function:\n",
    "        plots training and validation accuracy and loss curves to evaluate model performance over 10 epochs\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = training_history.history.get('accuracy', [])\n",
    "    val_accuracy = training_history.history.get('val_accuracy', [])\n",
    "    loss = training_history.history.get('loss', [])\n",
    "    val_loss = training_history.history.get('val_loss', [])\n",
    "    epochs = range(len(accuracy))\n",
    "\n",
    "    # Plot training validation accuracy curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, accuracy, 'bo', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training validation loss curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred_probs, class_indices: dict) -> float:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        y_true: true class labels\n",
    "        y_pred_probs: predicted probabilities for each class\n",
    "        class_indices - dict: mapping of class labels to class names\n",
    "\n",
    "    Function:\n",
    "        plots the receiver operating characteristic (ROC) curve for each class and calculates the macro-averaged\n",
    "        one vs rest (OvR) ROC AUC score\n",
    "\n",
    "    Returns:\n",
    "        macro averaged one vs rest ROC AUC score\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # ROC AUC reference: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "    # ROC curve and AUC for multi-class classification\n",
    "    y_true_bin = label_binarize(y_true, classes=list(range(len(class_indices))))\n",
    "    n_classes = y_true_bin.shape[1]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"red\", \"purple\", \"green\", \"gold\", \"deeppink\", \"brown\", \"gray\", \"navy\"])\n",
    "\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y_true_bin[:, i],\n",
    "            y_pred_probs[:, i],\n",
    "            name=f\"Class {i}\",\n",
    "            color=color,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "    # Macro average reference: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "    # Macro average ROC AUC score using OvR strategy\n",
    "    macro_roc_auc_ovo = roc_auc_score(y_true, \n",
    "                                      y_pred_probs, \n",
    "                                      multi_class=\"ovr\", \n",
    "                                      average=\"macro\")\n",
    "    \n",
    "    # ROC AUC plot reference: https://scikit-learn.org/1.1/auto_examples/model_selection/plot_roc.html\n",
    "    # Plot ROC AUC curve\n",
    "    ax.plot([0, 1], [0, 1], \"k--\", label=\"Chance Level (0.5)\")\n",
    "    ax.set(\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=\"ROC Curve\",\n",
    "    )\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    print(f\"Macro-averaged One-vs-Rest ROC AUC score: {macro_roc_auc_ovo:.2f}\")\n",
    "    return macro_roc_auc_ovo\n",
    "\n",
    "    \n",
    "def evaluation_metrics(model: tf.keras.Model, generator, training_history: tf.keras.callbacks.History) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluates trained model and returns evaluation metrics\n",
    "\n",
    "    Parameters:\n",
    "        model: trained model\n",
    "        generator: data generator for the evaluation set\n",
    "        training_history: object from model.fit() training history containing metrics accuracy and loss\n",
    "\n",
    "    Function:\n",
    "        combines evaluation metrics (classification report, confusion matrix, training curves, and ROC curve)\n",
    "        outputs key metrics: accuracy, precision, recall, and F1-score\n",
    "\n",
    "    Returns: \n",
    "        dictionary containing key metrics:\n",
    "            accuracy: model accuracy on the evaluation data\n",
    "            precision: macro averaged precision score\n",
    "            recall: macro averaged recall score\n",
    "            f1_score: macro averaged F1 score\n",
    "            classification_report_df: classification report as a dataframe\n",
    "\n",
    "    Outputs:\n",
    "        confusion matrix plot\n",
    "        loss plots\n",
    "        macro average ROC curve plot\n",
    "        macro averaged one vs rest ROC AUC score\n",
    "    \"\"\"\n",
    "\n",
    "    # Get true labels\n",
    "    y_true = generator.classes\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred_probs = model.predict(generator)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    class_indices = generator.class_indices\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Classification report\n",
    "    report_df = create_classification_report(y_true, y_pred, class_indices)\n",
    "\n",
    "    # Confusion matrix\n",
    "    plot_confusion_matrix(y_true, y_pred, class_indices)\n",
    "    \n",
    "    # Loss curves\n",
    "    plot_loss_curves(training_history)\n",
    "\n",
    "    # ROC AUC OvR score\n",
    "    macro_roc_auc_ovo = plot_roc_curve(y_true, y_pred_probs, class_indices)\n",
    "\n",
    "    # Get metrics from the classification report\n",
    "    precision = round(report_df.loc[\"macro avg\", \"precision\"], 3)\n",
    "    recall = round(report_df.loc[\"macro avg\", \"recall\"], 3)\n",
    "    f1_score = round(report_df.loc[\"macro avg\", \"f1-score\"], 3)\n",
    "\n",
    "    # Print key metrics\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": round(accuracy, 3),\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"classification_report_df\": report_df\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run, train, and evaluate the 7 different models\n",
    "    \"\"\"\n",
    "\n",
    "    # Store the results of the trained models\n",
    "    results = {}\n",
    "\n",
    "    # Train and evaluate the basic CNN model\n",
    "    print(\"Training Basic CNN Model...\")\n",
    "    basic_cnn_model, basic_training_history = full_build_cnn(epoch_num=DEFAULT_EPOCHS)\n",
    "    basic_test_loss, basic_test_acc = evaluate_model(basic_cnn_model, filename=\"pest_classifier_cnn_basic.h5\")\n",
    "    results[\"Basic_CNN\"] = evaluation_metrics(basic_cnn_model, EVAL_VAL_GENERATOR, basic_training_history)\n",
    "\n",
    "    # Train and evaluate each transfer learning model\n",
    "    for model_name in MODEL_OPTIONS:\n",
    "        print(f\"\\nTraining {model_name} Transfer Learning Model...\")\n",
    "        model, training_history = full_build_cnn(\n",
    "            use_transfer_learning=True, \n",
    "            transfer_model_name=model_name, \n",
    "            epoch_num=DEFAULT_EPOCHS\n",
    "        )\n",
    "        filename = f\"pest_classifier_cnn_{model_name.lower()}.h5\"\n",
    "        test_loss, test_acc = evaluate_model(model, filename=filename)\n",
    "        results[model_name] = evaluation_metrics(model, EVAL_VAL_GENERATOR, training_history)\n",
    "\n",
    "    print(\"Training and evaluation complete.\")\n",
    "    return results\n",
    "# --------------------------------------------------------------------------\n",
    "    # TEST CASE / EXPECTED RESULTS when this script is run:\n",
    "\n",
    "        # For each model, output should contain classification report, confusion matrix, \n",
    "        # accuracy/loss curves, ROC curves, accuracy, precision, recall, and F1 score\n",
    "        \n",
    "        # Seven .h5 files pertaining to the 7 pretrained models\n",
    "\n",
    "    \n",
    "        # time completion: ~5-6 hours\n",
    "    # --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

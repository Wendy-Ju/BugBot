{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b45ffaa-4f99-4144-93b8-74cdee700fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6114 images belonging to 11 classes.\n",
      "Found 440 images belonging to 11 classes.\n",
      "Found 220 images belonging to 11 classes.\n",
      "MobileNetV2, bayes: <function build_transfer_learning_MobileNetV2 at 0x172e6d1c0>\n",
      "MobileNetV2, random_search: <function build_transfer_learning_MobileNetV2 at 0x172e6d1c0>\n",
      "Xception, bayes: <function build_transfer_learning_Xception at 0x353a618a0>\n",
      "Xception, random_search: <function build_transfer_learning_Xception at 0x353a618a0>\n",
      "DenseNet201, bayes: <function build_transfer_learning_DenseNet201 at 0x172e6d120>\n",
      "DenseNet201, random_search: <function build_transfer_learning_DenseNet201 at 0x172e6d120>\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, Xception, DenseNet201\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import itertools\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, RocCurveDisplay\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_tuner import HyperParameters \n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "# ----------- CONSTANTS ----------------\n",
    "\n",
    "# define directory structure\n",
    "TRAIN_DIR = \"PROCESSED_DATA/TRAINING_DATA/TRAINING_AUGMENTED_DATA\"\n",
    "VALID_DIR = \"PROCESSED_DATA/VALIDATION_DATA/\"\n",
    "TEST_DIR = \"PROCESSED_DATA/TEST_DATA/\"\n",
    "\n",
    "# Image params\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NORMALIZE_FLAG = True\n",
    "NO_FRILLS_DATAGEN = ImageDataGenerator()\n",
    "NORM_DATAGEN = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "def load_data(directory,shuffle_flag=True):\n",
    "    '''\n",
    "    Param: \n",
    "        - directory - str, \n",
    "        - shuffle_flag - boolean, introduces constrolled stochasticity\n",
    "    '''\n",
    "    if NORMALIZE_FLAG == True:\n",
    "        generator = NORM_DATAGEN.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',shuffle=shuffle_flag)\n",
    "        return generator\n",
    "    else:\n",
    "        generator = NO_FRILLS_DATAGEN.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',shuffle=shuffle_flag)\n",
    "        return generator\n",
    "\n",
    "TRAIN_GENERATOR = load_data(TRAIN_DIR)\n",
    "VAL_GENERATOR = load_data(VALID_DIR)\n",
    "TEST_GENERATOR = load_data(TEST_DIR,shuffle_flag=False)\n",
    "EVAL_VAL_GENERATOR = load_data(VALID_DIR, shuffle_flag=False)\n",
    "\n",
    "hp = HyperParameters()\n",
    "\n",
    "\n",
    "# HP MODEL GENERATOR FUNCTIONS TO BE USED IN BEST MODEL WITH TUNED PARAMS\n",
    "\n",
    "def build_transfer_learning_MobileNetV2(hp):\n",
    "\n",
    "    '''hp tuning function specifically for MobileNetV2'''\n",
    "    \n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        \n",
    "    # freeze the base model layers\n",
    "    base_model.trainable = False  \n",
    "\n",
    "    dropout_rate = hp.Float(\"dropout\", min_value=0.2, max_value=0.5, step=0.1)\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    \n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    output_layer = Dense(TRAIN_GENERATOR.num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "    # tune \n",
    "    learning_rate = hp.Choice('lr', values=[1e-2, 1e-3, 1e-4])\n",
    "    batch_size = hp.Choice('batch_size', values=[16, 32, 64])\n",
    "    epochs = hp.Choice('epochs', values=[5, 10, 15, 25, 50, 100])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    # tune learning rate, batch size\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_transfer_learning_DenseNet201(hp):\n",
    "\n",
    "    '''hp tuning function specifically for DenseNet201'''\n",
    "    \n",
    "    base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        \n",
    "    # freeze the base model layers\n",
    "    base_model.trainable = False  \n",
    "\n",
    "    dropout_rate = hp.Float(\"dropout\", min_value=0.2, max_value=0.5, step=0.1)\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    output_layer = Dense(TRAIN_GENERATOR.num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "    # tune \n",
    "    learning_rate = hp.Choice('lr', values=[1e-2, 1e-3, 1e-4])\n",
    "    batch_size = hp.Choice('batch_size', values=[16, 32, 64])\n",
    "    epochs = hp.Choice('epochs', values=[5, 10, 15, 25, 50, 100])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    # tune learning rate, batch size\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def build_transfer_learning_Xception(hp):\n",
    "\n",
    "    '''hp tuning function specifically for Xception'''\n",
    "    \n",
    "    base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        \n",
    "    # freeze the base model layers\n",
    "    base_model.trainable = False  \n",
    "\n",
    "    dropout_rate = hp.Float(\"dropout\", min_value=0.2, max_value=0.5, step=0.1)\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    \n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    output_layer = Dense(TRAIN_GENERATOR.num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "    # tune \n",
    "    learning_rate = hp.Choice('lr', values=[1e-2, 1e-3, 1e-4])\n",
    "    batch_size = hp.Choice('batch_size', values=[16, 32, 64])\n",
    "    epochs = hp.Choice('epochs', values=[5, 10, 15, 25, 50, 100])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    # tune learning rate, batch size\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# BUILD BEST MODEL WITH TUNED PARAMS\n",
    "def build_best_model_transfer_learning(algorithm, model_name, hp_function):\n",
    "    '''\n",
    "    Param: algorithm - string in ['bayes', 'random_search'], \n",
    "            model_name - string version of model\n",
    "    Use: Build the best model using the desired algorithm to get the best hyperparameter \n",
    "    based on validation accuracy\n",
    "    '''\n",
    "\n",
    "    if algorithm == 'bayes':\n",
    "        # Define the Bayesian tuner\n",
    "        tuner = kt.BayesianOptimization(\n",
    "            hp_function,\n",
    "            objective='val_accuracy',  # tune by improving validation accuracy\n",
    "            max_trials=20,  # num different hp combos to try\n",
    "            executions_per_trial=1,  # run each model once\n",
    "            directory='bayesian_tuning',\n",
    "            project_name=f'bayes_hp_tuning_{model_name}'\n",
    "        )\n",
    "    elif algorithm == 'random_search':\n",
    "        tuner = kt.RandomSearch(\n",
    "        hp_function,  # Your model-building function\n",
    "        objective='val_accuracy',  # Tune for validation accuracy\n",
    "        max_trials=20,  # Number of different hyperparameter combinations to try\n",
    "        executions_per_trial=1,  # Number of times to run each model\n",
    "        directory='random_search_tuning',  # Directory to store tuning results\n",
    "        project_name=f'random_search_hp_tuning_{model_name}'\n",
    "    )\n",
    "    else:\n",
    "        raise ValueError(\"algorithm choice must be entered as string bayes or random_search \")\n",
    "        \n",
    "    \n",
    "    # search hp combos\n",
    "    tuner.search(TRAIN_GENERATOR, validation_data=VAL_GENERATOR, epochs=10)\n",
    "    \n",
    "    # get best hps\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    # save them\n",
    "    best_hps_dict = {'best_lr': best_hps.get('lr'),\n",
    "                    'best_dropout': best_hps.get('dropout'),\n",
    "                    'best_batch_size': best_hps.get('batch_size'),\n",
    "                    'best_epochs': best_hps.get('epochs')}\n",
    "    \n",
    "    # make final model with the best drop out, learning rate and batch size\n",
    "    best_model = tuner.hypermodel.build(best_hps)\n",
    "    best_model_training_history = best_model.fit(TRAIN_GENERATOR, validation_data=VAL_GENERATOR, epochs=best_hps.get('epochs'), batch_size=best_hps.get('batch_size'))\n",
    "\n",
    "    return best_hps_dict, best_model, best_model_training_history\n",
    "\n",
    "\n",
    "def evaluate_model_and_save(model, filename):\n",
    "    '''\n",
    "    Param: model - trained keras model object, \n",
    "            filename - name of fiel to save (extension must b .h5)\n",
    "    Use: Saves model to h5 file, returns TEST accuracy loss and test accuracy\n",
    "    '''\n",
    "    \n",
    "    # evaluate on test data\n",
    "    test_loss, test_acc = model.evaluate(TEST_GENERATOR)\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # save to file\n",
    "    model.save(filename)\n",
    "\n",
    "    return test_loss, test_acc\n",
    "\n",
    "\n",
    "def get_model_and_algorithm_combos_dict():\n",
    "    \n",
    "     # dict of top 3 models to tune from eda without tuning and associated hp functions\n",
    "    models_to_tune = {'MobileNetV2': build_transfer_learning_MobileNetV2,\n",
    "                      'Xception': build_transfer_learning_Xception,\n",
    "                      'DenseNet201': build_transfer_learning_DenseNet201}\n",
    "\n",
    "    hp_algorithms = ['bayes', 'random_search']\n",
    "\n",
    "    # get all possible combinations to run\n",
    "    combinations_dict = {} \n",
    "\n",
    "    #iterate through 3 models\n",
    "    for model_name, model_fn in models_to_tune.items():\n",
    "        \n",
    "        # go through hp algos\n",
    "        for algo in hp_algorithms:\n",
    "            combinations_dict[(model_name, algo)] = model_fn\n",
    "\n",
    "    return combinations_dict\n",
    "    \n",
    "\n",
    "\n",
    "# MODEL EVALUATION Functions ------\n",
    "\n",
    "def create_classification_report(y_true, y_pred, class_indices):\n",
    "    '''\n",
    "    Params:\n",
    "        y_true: true class labels\n",
    "        y_pred: predicted class labels\n",
    "        class_indices: mapping of class labels to class names.\n",
    "\n",
    "    Function:\n",
    "        generates a classification report including precision, recall, F1-score, and accuracy for each class\n",
    "        outputs the report as a DataFrame for further analysis\n",
    "\n",
    "    Returns:\n",
    "        classification report as a dataframe\n",
    "    '''\n",
    "    report = classification_report(y_true, y_pred, target_names=list(class_indices.keys()), output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    print(\"Classification Report:\")\n",
    "    display(report_df)\n",
    "    return report_df\n",
    "\n",
    "    \n",
    "def plot_confusion_matrix(y_true, y_pred, class_indices):\n",
    "    '''\n",
    "    Params:\n",
    "        y_true: true class labels\n",
    "        y_pred: predicted class labels\n",
    "        class_indices: Mapping of class labels to class names\n",
    "\n",
    "    Function:\n",
    "        Plots a confusion matrix\n",
    "\n",
    "    '''\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(class_indices.keys()))\n",
    "    disp.plot(cmap=plt.cm.Blues, colorbar=True)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_loss_curves(training_history):\n",
    "    '''\n",
    "    Params:\n",
    "        training_history: object from model.fit() training history containing metrics accuracy and loss\n",
    "\n",
    "    Function:\n",
    "        plots training and validation accuracy and loss curves to evaluate model performance over epochs\n",
    "\n",
    "    '''\n",
    "    accuracy = training_history.history.get('accuracy', [])\n",
    "    val_accuracy = training_history.history.get('val_accuracy', [])\n",
    "    loss = training_history.history.get('loss', [])\n",
    "    val_loss = training_history.history.get('val_loss', [])\n",
    "    epochs = range(len(accuracy))\n",
    "\n",
    "    # Plot training validation accuracy curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, accuracy, 'bo', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training validation loss curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred_probs, class_indices):\n",
    "    '''\n",
    "    Params:\n",
    "        y_true: true class labels\n",
    "        y_pred_probs: predicted probabilities for each class\n",
    "        class_indices: mapping of class labels to class names\n",
    "\n",
    "    Function:\n",
    "        plots the receiver operating characteristic (ROC) curve for each class and calculates the macro-averaged\n",
    "        one vs rest (OvR) ROC AUC score\n",
    "\n",
    "    Returns:\n",
    "        macro averaged one vs rest ROC AUC score\n",
    "    '''\n",
    "\n",
    "    # ROC AUC reference: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "    # ROC curve and AUC for multi-class classification\n",
    "    y_true_bin = label_binarize(y_true, classes=list(range(len(class_indices))))\n",
    "    n_classes = y_true_bin.shape[1]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"red\", \"purple\", \"green\", \"gold\", \"deeppink\", \"brown\", \"gray\", \"navy\"])\n",
    "\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y_true_bin[:, i],\n",
    "            y_pred_probs[:, i],\n",
    "            name=f\"Class {i}\",\n",
    "            color=color,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "    # Macro average reference: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "    # Macro average ROC AUC score using OvR strategy\n",
    "    macro_roc_auc_ovo = roc_auc_score(y_true, \n",
    "                                      y_pred_probs, \n",
    "                                      multi_class=\"ovr\", \n",
    "                                      average=\"macro\")\n",
    "    \n",
    "    # ROC AUC plot reference: https://scikit-learn.org/1.1/auto_examples/model_selection/plot_roc.html\n",
    "    # Plot ROC AUC curve\n",
    "    ax.plot([0, 1], [0, 1], \"k--\", label=\"Chance Level (0.5)\")\n",
    "    ax.set(\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=\"ROC Curve\",\n",
    "    )\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    print(f\"Macro-averaged One-vs-One ROC AUC score: {macro_roc_auc_ovo:.2f}\")\n",
    "    return macro_roc_auc_ovo\n",
    "\n",
    "    \n",
    "def evaluation_metrics(model, generator, training_history):\n",
    "    '''\n",
    "    Params:\n",
    "        model: trained model\n",
    "        generator: data generator for the evaluation set\n",
    "        training_history: object from model.fit() training history containing metrics accuracy and loss\n",
    "\n",
    "    Function:\n",
    "        combines evaluation metrics (classification report, confusion matrix, training curves, and ROC curve)\n",
    "        outputs key metrics: accuracy, precision, recall, and F1-score\n",
    "\n",
    "    Returns: \n",
    "        dictionary containing:\n",
    "            accuracy: model accuracy on the evaluation data\n",
    "            precision: macro averaged precision score\n",
    "            recall: macro averaged recall score\n",
    "            f1_score: macro averaged F1 score\n",
    "            classification_report_df: classification report as a dataframe\n",
    "\n",
    "    Outputs:\n",
    "        confusion matrix plot\n",
    "        loss plots\n",
    "        macro average ROC curve plot\n",
    "        macro averaged one vs rest ROC AUC score\n",
    "    '''\n",
    "    \n",
    "    # Get true labels\n",
    "    y_true = generator.classes\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred_probs = model.predict(generator)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    class_indices = generator.class_indices\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Classification report\n",
    "    report_df = create_classification_report(y_true, y_pred, class_indices)\n",
    "\n",
    "    # Confusion matrix\n",
    "    plot_confusion_matrix(y_true, y_pred, class_indices)\n",
    "    \n",
    "    # Loss curves\n",
    "    plot_loss_curves(training_history)\n",
    "\n",
    "    # ROC AUC OvR score\n",
    "    macro_roc_auc_ovo = plot_roc_curve(y_true, y_pred_probs, class_indices)\n",
    "\n",
    "    # Get metrics from the classification report\n",
    "    precision = round(report_df.loc[\"macro avg\", \"precision\"], 3)\n",
    "    recall = round(report_df.loc[\"macro avg\", \"recall\"], 3)\n",
    "    f1_score = round(report_df.loc[\"macro avg\", \"f1-score\"], 3)\n",
    "\n",
    "    # Print key metrics\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": round(accuracy, 3),\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"classification_report_df\": report_df\n",
    "    }\n",
    "\n",
    "\n",
    "    \n",
    "def main():\n",
    "\n",
    "    print('--- MAKING MODEL x HP ALGORITHM COMBINATIONS ---')\n",
    "    combos_to_run = get_model_and_algorithm_combos_dict()\n",
    "    print('model-alg combinations:',combos_to_run)\n",
    "\n",
    "    # there should be 6 model combo results\n",
    "    results_dict = {}\n",
    "\n",
    "    count = 0\n",
    "    for key, funct in combos_to_run.items():\n",
    "        \n",
    "        print(f' --- STARTING MODEL COMBO {count+1}/6 --- ')\n",
    "        count = count + 1\n",
    "        \n",
    "        this_algorithm = key[1] # which hp algo to use\n",
    "        this_model_name = key[0] # which model to use\n",
    "        this_hp_function = funct # which hp tuning func to use\n",
    "\n",
    "        # getting results for this model and optimization alg\n",
    "        best_hps_dict, best_model, best_model_training_history = build_best_model_transfer_learning(\n",
    "            algorithm = this_algorithm, \n",
    "            model_name=this_model_name, \n",
    "            hp_function=this_hp_function)\n",
    "        \n",
    "        # get final model metrics on test set and save trained model to unique file \n",
    "\n",
    "        save_model_filename = f\"{this_model_name}_{this_algorithm}.h5\"\n",
    "        this_test_loss, this_test_acc = evaluate_model_and_save(best_model, filename = save_model_filename)\n",
    "        print(f' ---- Completed saving: {this_model_name}_{this_algorithm}.h5 ---- ')\n",
    "\n",
    "        # Print results\n",
    "        print(f'Model: {this_model_name}, HP Algorithm: {this_algorithm}, test_loss: {this_test_loss}, test_acc: {this_test_acc}')\n",
    "    \n",
    "        # save results in dictionary for comparison yeet\n",
    "        \n",
    "        best_validation_accuracy = best_hps_dict[\"accuracy\"]\n",
    "        best_validation_precision = best_hps_dict[\"precision\"]\n",
    "        best_validation_recall = best_hps_dict[\"recall\"]\n",
    "        best_validation_f1_score = best_hps_dict[\"f1_score\"]\n",
    "\n",
    "        results_dict[f'{this_model_name}_{this_algorithm}'] = {\n",
    "            \"test_loss\": this_test_loss,\n",
    "            \"test_accuracy\": this_test_acc,\n",
    "            \"best_validation_accuracy\": best_validation_accuracy,\n",
    "            \"best_validation_precision\": best_validation_precision,\n",
    "            \"best_validation_recall\": best_validation_recall,\n",
    "            \"best_validation_f1_score\": best_validation_f1_score\n",
    "        }\n",
    "\n",
    "        # prints final metrics for insight into training process and validation metrics\n",
    "        printing_model_metrics = evaluation_metrics(best_model, EVAL_VAL_GENERATOR, best_model_training_history)\n",
    "\n",
    "        \n",
    "        print(f\"Completed this model combo: {this_model_name}_{this_algorithm}\\n\\n\")\n",
    "\n",
    "        # clear keras session to free memory\n",
    "        K.clear_session()\n",
    "\n",
    "    # save final csv with all info!\n",
    "    df_results = pd.DataFrame(results_dict)\n",
    "    df.to_csv('final_tuned_models_results.csv')\n",
    "\n",
    "        \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca5c01-7ba2-4620-bd77-08e653d18a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
